{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1qpSfYkQoAs"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8vXsr6xQ4Du",
        "outputId": "687c48a8-cf1f-4993-8fde-fff56909b24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"tqdm version:\", tqdm.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the weights"
      ],
      "metadata": {
        "id": "98tuVKett-lo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtoRFt6fQ72O"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/llm_s')\n",
        "\n",
        "from gpt_download3 import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8e-VftnSPEP",
        "outputId": "f945627c-162f-4d4e-d27f-e9cecb469b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: /content/drive/MyDrive/llm_m/355M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"355M\", models_dir=\"/content/drive/MyDrive/llm_m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d6_hZ5SSazi",
        "outputId": "a293ac54-9e0b-4770-d790-f8bba2e6b918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1024, 'n_head': 16, 'n_layer': 24}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSAD8GmcSc9O",
        "outputId": "2baee300-848b-4bd0-9e90-257aa3d4c36a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.0115168   0.00311915 -0.00729894 ... -0.05262156 -0.17569277\n",
            "   0.02565791]\n",
            " [-0.00861426  0.06360211 -0.01822355 ... -0.01364703 -0.12153847\n",
            "   0.05352487]\n",
            " [ 0.05854857  0.06891199  0.02622696 ... -0.10057542 -0.19788682\n",
            "  -0.0039184 ]\n",
            " ...\n",
            " [ 0.00162342 -0.04411932 -0.0517492  ... -0.10079621 -0.00865952\n",
            "   0.02637872]\n",
            " [-0.14374605 -0.04632217 -0.00650705 ...  0.07464293 -0.04721651\n",
            "  -0.03829013]\n",
            " [ 0.02065966 -0.01334631 -0.02586888 ...  0.03886637 -0.00233481\n",
            "   0.00107106]]\n",
            "Token embedding weight tensor dimensions: (50257, 1024)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWaFMfyhTogM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H_5ESjETcg8"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CZh8EH7TPe7"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMiSDygUTLtg"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9zUV2IVVbgQ"
      },
      "outputs": [],
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "# model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jgG2Cd_TG2k"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        " # Disable dropout during inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvnCG8UuT_3H"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkt6ivGAUEoy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M2Ls472Z5bz"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctcLIbI9UIqR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyzE1r0dXBvu",
        "outputId": "63b50197-8e2b-4eca-955f-5a68510a5bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH4nNvi6UbTB"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2sQ3WVZUjju",
        "outputId": "5ac443c2-4b74-454b-d953-d236b3c0f69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbD59CAnUhhC"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    encoded_tensor = encoded_tensor.to(device)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Current output of model"
      ],
      "metadata": {
        "id": "qIB0_ueGuH65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuEgx9MUXnv",
        "outputId": "b872800e-cad7-4e37-9c42-607384dd58b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every efforts moves you closer to the truth, and you're more likely to be able to understand what's really going on.\n",
            "\n",
            "When I was young, I had a friend who was a journalist. He was a very good writer, and he was very good at\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "gpt=model\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every efforts moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=50,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the instruction Dataset"
      ],
      "metadata": {
        "id": "yLQ5r572uQ5m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Yp4-BZVbbu",
        "outputId": "e8c1cbd2-5ea0-4bde-fa3b-88f2c7f3e4b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PdZpgroVbbx",
        "outputId": "3d9a786b-d82b-4a0e-e1eb-08c0d2373df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-hID9wPVbb0",
        "outputId": "0e6b5b24-81f0-4718-fa59-b88fbc93ac65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBnhj7snVbb5"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZCoLcG4Vbb-",
        "outputId": "4321f5d6-2697-4fc2-9bae-1e22bd1f0b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pg4LpHKVbcW",
        "outputId": "580a9db6-616a-4f58-f259-3c8c8056a900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV7cStyzVbcb"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PisSWzA8Vbch",
        "outputId": "1d9eb45e-6823-4b8b-b577-596262a77793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3q1SCW-Vbc2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdytbH3EVbdA",
        "outputId": "afa9b053-09c6-4c4f-bcca-ab79edfd77fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating DataLoaders"
      ],
      "metadata": {
        "id": "nVVK9CJ_univ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urc_baVAVbeM"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVQfR1TYdjiS",
        "outputId": "d8db0162-ced6-484e-eb1a-b3aa27d26fe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHsnqogIVbea",
        "outputId": "61093d80-39c9-4b0e-db25-7de3bf3fdb6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aHwjGtiVbem",
        "outputId": "d565a3f9-fdb3-4bdd-b596-891c8a767440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],  # 1st training example\n",
        "     [-0.5, 1.5]]  # 2nd training example\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mudZcvxlVbes",
        "outputId": "f160731f-ea93-4ad8-906f-6a16f7cec00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sCked13Vbe2",
        "outputId": "9a85851e-13ca-48fd-c310-ef077f35cc79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # New 3rd training example\n",
        ")\n",
        "\n",
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YWhA7aoVbfk"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Note:\n",
        "# # Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# # which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# # However, the resulting loss values may be slightly different.\n",
        "\n",
        "# #if torch.cuda.is_available():\n",
        "# #    device = torch.device(\"cuda\")\n",
        "# #elif torch.backends.mps.is_available():\n",
        "# #    device = torch.device(\"mps\")\n",
        "# #else:\n",
        "# #    device = torch.device(\"cpu\")\n",
        "\n",
        "# print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiLXLmchVbfu"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow5FHyX3Vbfz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkz5UozVVbf8",
        "outputId": "65608174-8470-4bdf-cf77-49711d8cabb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmPon4RacePm"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Current response to instructions"
      ],
      "metadata": {
        "id": "DT2_AkT7uzqw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3JtfLInVbge",
        "outputId": "d64cfcea-1d1e-4359-e060-fc6fdc2f0fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpjo_hYDfPea"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkbvR84EVbgg"
      },
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZRVa2zIVbgw",
        "outputId": "3cbc7536-05a9-41a1-c64b-7eab72cb7f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tuning"
      ],
      "metadata": {
        "id": "jjmilYv9u7uS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnGTkU-cVbhL"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M7PLRMVVbhQ",
        "outputId": "a7f3a1ab-dac0-4622-bca2-96d84b72ebc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uElYtQgVeU1Q"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ3CZx7_VbUj"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVgQAcFZVbha",
        "outputId": "fd0b6f41-e2d9-4601-d5a9-b29871ee7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.509, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.668\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.634\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.634\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.362, Val loss 0.631\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.341, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.13 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkPERq6WVbhe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "pWNywjKaVbhg",
        "outputId": "93f7e82d-36b9-4ea9-b7a5-7294ed983de9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gONzk9s7j8HI"
      },
      "source": [
        "#After 2 epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIZDNVPHj7Ub",
        "outputId": "a05ee42f-2b93-41b6-dbb6-02a0647f289b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of storm that typically produces a strong wind and/or rain.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5pFrLfbsPze",
        "outputId": "c608e5a1-b0bc-40de-eaa2-8c90eb547066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "model = GPTModel(BASE_CONFIG)\n",
        "\n",
        "# Load the weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/llm_m/gpt2_medium_loaded-mft2.pth\", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoT3S-JmVbiO",
        "outputId": "58b91804-cd86-458f-9c45-1ac6d532be56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:13<00:00,  1.49it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/llm_m/instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaSzMYzJVbiS",
        "outputId": "dcf22506-7220-421a-8813-305518764ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szEzl-4_iZhn",
        "outputId": "cee4468a-f005-4841-a383-ddd1abc42f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/llm_m/gpt2_medium_loaded-mft-2eps.pth\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##You can see the current output of model on test Data which It haven't see during training loop 📊"
      ],
      "metadata": {
        "id": "Prg1WAAWvHUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCCqLmggETDe",
        "outputId": "8ab68f07-2681-4306-e634-bcdbfd432953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'instruction': 'Rewrite the sentence using a simile.',\n",
              "  'input': 'The car is very fast.',\n",
              "  'output': 'The car is as fast as lightning.',\n",
              "  'model_response': 'The car is as fast as a bullet.'},\n",
              " {'instruction': 'What type of cloud is typically associated with thunderstorms?',\n",
              "  'input': '',\n",
              "  'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.',\n",
              "  'model_response': 'The type of cloud associated with thunderstorms is a cumulus cloud.'},\n",
              " {'instruction': \"Name the author of 'Pride and Prejudice'.\",\n",
              "  'input': '',\n",
              "  'output': 'Jane Austen.',\n",
              "  'model_response': \"The author of 'Pride and Prejudice' is Jane Austen.\"},\n",
              " {'instruction': 'What is the periodic symbol for chlorine?',\n",
              "  'input': '',\n",
              "  'output': 'The periodic symbol for chlorine is Cl.',\n",
              "  'model_response': 'The periodic symbol for chlorine is C.'},\n",
              " {'instruction': 'Correct the punctuation in the sentence.',\n",
              "  'input': 'Its time to go home.',\n",
              "  'output': \"The corrected sentence should be: 'It's time to go home.'\",\n",
              "  'model_response': \"It's time to go home.\"},\n",
              " {'instruction': 'Rewrite the sentence.',\n",
              "  'input': 'The lecture was delivered in a clear manner.',\n",
              "  'output': 'The lecture was delivered clearly.',\n",
              "  'model_response': 'The lecture was delivered in a clear manner.'},\n",
              " {'instruction': 'Generate a humorous anecdote.',\n",
              "  'input': '',\n",
              "  'output': 'Why was the math book sad? Because it had too many problems!',\n",
              "  'model_response': 'I was at a party last night. A few friends were having a good time. One of them said, \"I\\'m so tired I could sleep for a year.\"'},\n",
              " {'instruction': \"Identify the correct spelling: 'recieve' or 'receive'.\",\n",
              "  'input': '',\n",
              "  'output': \"The correct spelling is 'receive'.\",\n",
              "  'model_response': \"The correct spelling is 'receive'.\"},\n",
              " {'instruction': \"Create a sentence using the word 'nostalgia'.\",\n",
              "  'input': '',\n",
              "  'output': 'Nostalgia washed over her as she looked through the old photos.',\n",
              "  'model_response': 'I was very nostalgic for my childhood.'},\n",
              " {'instruction': 'Classify the following numbers as prime or composite.',\n",
              "  'input': ': 11, 14, 19.',\n",
              "  'output': 'Prime numbers: 11, 19\\nComposite numbers: 14',\n",
              "  'model_response': 'Prime numbers: 11, 14, 19\\nComposite numbers: 19'}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUuewlwKHhvh"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}